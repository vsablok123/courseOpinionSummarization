{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import scipy.sparse as sparse\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import spacy\n",
    "import en_core_web_lg\n",
    "from spacy import displacy\n",
    "nlp = en_core_web_lg.load()\n",
    "from starterUtil import getCourseReviewsbyTag, getTagsList\n",
    "from preprocessing_Util import generateCleanDF, removeStopwords\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLUSTERS = 100\n",
    "\n",
    "topNounWords = {}\n",
    "tags = getTagsList()\n",
    "cleanDFwoStopwords = pd.read_csv(\"cleanReviewswithoutStopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTopNounDict(tag):\n",
    "    if tag == ' ':\n",
    "        cleanedCorpus = cleanDFwoStopwords['reviews']\n",
    "    else:\n",
    "        cleanedCorpus = cleanDFwoStopwords[cleanDFwoStopwords['Tags'] == tag]['reviews']\n",
    "    noun_dict = {}\n",
    "    nounTags = ['NN','NNS','NNP','NNPS']\n",
    "    for review in cleanedCorpus:\n",
    "        tokens = word_tokenize(str(review))\n",
    "        postags = get_postags(tokens)\n",
    "        for i in range(len(postags)):\n",
    "            if postags[i] in nounTags:\n",
    "                if tokens[i] in noun_dict:\n",
    "                    noun_dict[tokens[i]] += 1\n",
    "                else:\n",
    "                    noun_dict[tokens[i]] = 1\n",
    "    #Finding the most appearing nouns\n",
    "\n",
    "    for key,value in noun_dict.items():\n",
    "        if value > 500:\n",
    "            topNounWords[key] = value\n",
    "    return topNounWords\n",
    "                    \n",
    "def get_postags(row):\n",
    "    \n",
    "    postags = nltk.pos_tag(row)\n",
    "    list_classes = list()\n",
    "    for  word in postags:\n",
    "        list_classes.append(word[1])\n",
    "    \n",
    "    return list_classes\n",
    "\n",
    "def clusteredTopNouns(tag):\n",
    "    topNounWords = createTopNounDict(tag)\n",
    "        \n",
    "\n",
    "    spell = SpellChecker(distance=2)  # set at initialization\n",
    "    misspelled = spell.unknown(list(topNounWords.keys()))\n",
    "    for word in misspelled:\n",
    "        if spell.correction(word) in topNounWords:\n",
    "            topNounWords[spell.correction(word)] = topNounWords[spell.correction(word)] + topNounWords.pop(word)\n",
    "     \n",
    "    wordvectors = {}\n",
    "    for index,row in topNounWords.items():\n",
    "        wordvector = nlp(index).vector\n",
    "        wordvectors[index] = wordvector\n",
    "        \n",
    "    X = np.zeros((len(wordvectors),300))\n",
    "    for i, (word, vector) in enumerate(wordvectors.items()):\n",
    "        X[i] = vector\n",
    "\n",
    "    kmeans = cluster.KMeans(n_clusters=NUM_CLUSTERS,max_iter=1000)\n",
    "    kmeans.fit(X)       \n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    clusters = {}\n",
    "    for (word,label) in zip([*wordvectors] , labels):\n",
    "\n",
    "        count = topNounWords[word]\n",
    "        if label in clusters:\n",
    "            clusters[label].append((word, count))\n",
    "        else:\n",
    "            clusters[label] = [(word,count)]\n",
    "            \n",
    "    filteredFeatures = {}\n",
    "    for i,clster in enumerate(clusters):\n",
    "        counter = list(zip(*clusters[clster]))[1]\n",
    "        words = list(zip(*clusters[clster]))[0]\n",
    "        word = words[counter.index(max(counter))]\n",
    "        filteredFeatures[word] = max(counter)\n",
    "    \n",
    "    return filteredFeatures\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "topNouns = clusteredTopNouns(\"['Data Science', 'Machine Learning']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'course': 116607,\n",
       " 'understand': 4883,\n",
       " 'problems': 3737,\n",
       " 'details': 2992,\n",
       " 'week': 3349,\n",
       " 'way': 10391,\n",
       " 'questions': 1997,\n",
       " 'videos': 3897,\n",
       " 'learning': 20390,\n",
       " 'theory': 2591,\n",
       " 'programming': 5936,\n",
       " 'concepts': 14656,\n",
       " 'data': 3649,\n",
       " 'assignments': 14986,\n",
       " 'instructor': 3011,\n",
       " 'lot': 11602,\n",
       " 'field': 4086,\n",
       " 'students': 3345,\n",
       " 'part': 3569,\n",
       " 'Professor': 3569,\n",
       " 'things': 4646,\n",
       " 'functions': 1277,\n",
       " 'solutions': 570,\n",
       " 'notes': 1043,\n",
       " 'teaching': 1265,\n",
       " 'Andrew': 26154,\n",
       " 'Ng': 18674,\n",
       " 'machine': 21942,\n",
       " 'Python': 3594,\n",
       " 'lectures': 3905,\n",
       " 'ML': 11997,\n",
       " 'content': 4463,\n",
       " 'forums': 944,\n",
       " 'Prof.': 3385,\n",
       " 'team': 2689,\n",
       " 'level': 3700,\n",
       " 'nan': 34165,\n",
       " 'Great': 6140,\n",
       " 'knowledge': 8271,\n",
       " 'implementation': 2236,\n",
       " 'math': 4160,\n",
       " 'material': 5236,\n",
       " 'introduction': 7058,\n",
       " 'class': 6148,\n",
       " 'quizzes': 885,\n",
       " 'Coursera': 4703,\n",
       " 'practice': 3238,\n",
       " 'networks': 6230,\n",
       " 'algebra': 2054,\n",
       " 'Deep': 5075,\n",
       " 'help': 2979,\n",
       " 'Thank': 8896,\n",
       " 'techniques': 2614,\n",
       " 'models': 2495,\n",
       " 'points': 617,\n",
       " 'topics': 5328,\n",
       " 'helpful': 811,\n",
       " 'lab': 685,\n",
       " 'exercises': 6756,\n",
       " 'background': 2530,\n",
       " 'computer': 982,\n",
       " 'science': 1502,\n",
       " 'notebook': 989,\n",
       " 'Octave': 1843,\n",
       " 'specialization': 3773,\n",
       " 'foundation': 1539,\n",
       " 'Stanford': 885,\n",
       " 'basics': 4144,\n",
       " 'intuition': 2664,\n",
       " 'step': 2587,\n",
       " 'platform': 1158,\n",
       " 'NN': 1915,\n",
       " 'Neural': 3463,\n",
       " 'cases': 1035,\n",
       " 'study': 1337,\n",
       " 'projects': 1496,\n",
       " 'applications': 2930,\n",
       " 'stars': 1053,\n",
       " 'teacher': 3141,\n",
       " 'propagation': 1069,\n",
       " 'online': 1099,\n",
       " 'Matlab': 1265,\n",
       " 'tasks': 801,\n",
       " 'algorithms': 4485,\n",
       " 'tools': 1763,\n",
       " 'module': 519,\n",
       " 'industry': 771,\n",
       " 'regression': 872,\n",
       " 'curso': 595,\n",
       " 'Sir': 1209,\n",
       " 'Linear': 759,\n",
       " 'career': 1334,\n",
       " 'sequence': 755,\n",
       " 'optimization': 948,\n",
       " 'que': 622,\n",
       " 'Cloud': 780,\n",
       " 'AWS': 726,\n",
       " 'NLP': 825,\n",
       " 'GCP': 1568,\n",
       " 'hyperparameters': 1040}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topNouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def tagRelevantUnigramProb(unigrams, tag):\n",
    "    streamReviews = cleanDFwoStopwords[cleanDFwoStopwords['Tags'] == tag]['reviews'].apply(lambda x: str(x))\n",
    "    reviewText = \" \".join(streamReviews)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(reviewText)\n",
    "    unigramsProb = {}\n",
    "    for word, ct in unigrams.items():\n",
    "        count = phraseCountinText(str(word), reviewText)\n",
    "        if count != 0:\n",
    "            unigramsProb[word] = -np.log(count/len(words))\n",
    "    return unigramsProb  \n",
    "\n",
    "def allUnigramsProb(unigrams):\n",
    "    raw_text = \" \".join(cleanDFwoStopwords['reviews'].apply(lambda x: str(x)))\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(raw_text)\n",
    "    unigramsProb = {}\n",
    "    for word, ct in unigrams.items():\n",
    "        count = phraseCountinText(str(word),raw_text)\n",
    "        unigramsProb[word] = -np.log(count/len(words))\n",
    "    return unigramsProb        \n",
    "            \n",
    "def phraseCountinText(phrase, text):\n",
    "    return len(re.findall(phrase,text))\n",
    "            \n",
    "def getTagRelevantFeatures(tag, unigrams, threshold):\n",
    "    tagUnigramProb = tagRelevantUnigramProb(unigrams, tag)\n",
    "    allUnigramProb = allUnigramsProb(unigrams)\n",
    "    tagRelevantFeatures = {}\n",
    "    for i, word in enumerate(tagUnigramProb):\n",
    "        if allUnigramProb[word] - tagUnigramProb[word] > 0.8:\n",
    "            tagRelevantFeatures[word] = unigrams[word]\n",
    "    return tagRelevantFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagRelevantFeatures = getTagRelevantFeatures(\"['Data Science', 'Machine Learning']\", topNouns, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning': 20390,\n",
       " 'Andrew': 26154,\n",
       " 'Ng': 18674,\n",
       " 'machine': 21942,\n",
       " 'ML': 11997,\n",
       " 'implementation': 2236,\n",
       " 'math': 4160,\n",
       " 'networks': 6230,\n",
       " 'algebra': 2054,\n",
       " 'Deep': 5075,\n",
       " 'models': 2495,\n",
       " 'exercises': 6756,\n",
       " 'notebook': 989,\n",
       " 'Octave': 1843,\n",
       " 'Stanford': 885,\n",
       " 'intuition': 2664,\n",
       " 'NN': 1915,\n",
       " 'Neural': 3463,\n",
       " 'applications': 2930,\n",
       " 'propagation': 1069,\n",
       " 'Matlab': 1265,\n",
       " 'algorithms': 4485,\n",
       " 'regression': 872,\n",
       " 'Sir': 1209,\n",
       " 'Linear': 759,\n",
       " 'sequence': 755,\n",
       " 'optimization': 948,\n",
       " 'NLP': 825,\n",
       " 'hyperparameters': 1040}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagRelevantFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagsList = list(tags)\n",
    "tagsList.remove('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['Arts and Humanities', 'History']\",\n",
       " \"['Arts and Humanities', 'Music and Art']\",\n",
       " \"['Arts and Humanities', 'Philosophy']\",\n",
       " \"['Business', 'Business Essentials']\",\n",
       " \"['Business', 'Business Strategy']\",\n",
       " \"['Business', 'Entrepreneurship']\",\n",
       " \"['Business', 'Finance']\",\n",
       " \"['Business', 'Leadership and Management']\",\n",
       " \"['Business', 'Marketing']\",\n",
       " \"['Computer Science', 'Algorithms']\",\n",
       " \"['Computer Science', 'Computer Security and Networks']\",\n",
       " \"['Computer Science', 'Design and Product']\",\n",
       " \"['Computer Science', 'Mobile and Web Development']\",\n",
       " \"['Computer Science', 'Software Development']\",\n",
       " \"['Data Science', 'Data Analysis']\",\n",
       " \"['Data Science', 'Machine Learning']\",\n",
       " \"['Data Science', 'Probability and Statistics']\",\n",
       " \"['Health', 'Animal Health']\",\n",
       " \"['Health', 'Basic Science']\",\n",
       " \"['Health', 'Health Informatics']\",\n",
       " \"['Health', 'Healthcare Management']\",\n",
       " \"['Health', 'Nutrition']\",\n",
       " \"['Health', 'Patient Care']\",\n",
       " \"['Health', 'Psychology']\",\n",
       " \"['Health', 'Public Health']\",\n",
       " \"['Health', 'Research']\",\n",
       " \"['Information Technology', 'Cloud Computing']\",\n",
       " \"['Information Technology', 'Data Management']\",\n",
       " \"['Information Technology', 'Networking']\",\n",
       " \"['Information Technology', 'Security']\",\n",
       " \"['Information Technology', 'Support and Operations']\",\n",
       " \"['Language Learning', 'Learning English']\",\n",
       " \"['Language Learning', 'Other Languages']\",\n",
       " \"['Math and Logic', 'Math and Logic']\",\n",
       " \"['Personal Development', 'Personal Development']\",\n",
       " \"['Physical Science and Engineering', 'Chemistry']\",\n",
       " \"['Physical Science and Engineering', 'Electrical Engineering']\",\n",
       " \"['Physical Science and Engineering', 'Environmental Science and Sustainability']\",\n",
       " \"['Physical Science and Engineering', 'Mechanical Engineering']\",\n",
       " \"['Physical Science and Engineering', 'Physics and Astronomy']\",\n",
       " \"['Physical Science and Engineering', 'Research Methods']\",\n",
       " \"['Social Sciences', 'Economics']\",\n",
       " \"['Social Sciences', 'Education']\",\n",
       " \"['Social Sciences', 'Governance and Society']\",\n",
       " \"['Social Sciences', 'Law']\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiclass Sentiment Analyser\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "coursereviews = pd.read_csv(\"Coursera_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coursereviews.set_index('rating', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for index in range(1,6,1):\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>This course is virtually worthless.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I couldn't follow the lectures, and I have a P...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The online course is based on snippets taken f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>The instructor frequently refers to concepts t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>This online version of the Yale course was obv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51186</td>\n",
       "      <td>Some quizzes are senseless, the course itself ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51187</td>\n",
       "      <td>I did not receive my certificate, though have ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51188</td>\n",
       "      <td>The lessons and teachings do not match up with...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51189</td>\n",
       "      <td>i did'nt got my certificate and this site id v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51190</td>\n",
       "      <td>i did'nt got my certificate and this site id v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51191 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review rating\n",
       "0                    This course is virtually worthless.      1\n",
       "1      I couldn't follow the lectures, and I have a P...      1\n",
       "2      The online course is based on snippets taken f...      1\n",
       "3      The instructor frequently refers to concepts t...      1\n",
       "4      This online version of the Yale course was obv...      1\n",
       "...                                                  ...    ...\n",
       "51186  Some quizzes are senseless, the course itself ...      1\n",
       "51187  I did not receive my certificate, though have ...      1\n",
       "51188  The lessons and teachings do not match up with...      1\n",
       "51189  i did'nt got my certificate and this site id v...      1\n",
       "51190  i did'nt got my certificate and this site id v...      1\n",
       "\n",
       "[51191 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData = pd.DataFrame(columns = ['review','rating'])\n",
    "sentencelist = sum(list(map(lambda x: sent_tokenize(str(x)),coursereviews.loc[1]['reviews'])),[])\n",
    "count = len(sentencelist)\n",
    "pd.DataFrame(data = [sentencelist, [1]*count], index=['review','rating']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51191\n",
      "48399\n",
      "109798\n",
      "95481\n",
      "93775\n"
     ]
    }
   ],
   "source": [
    "trainingData = pd.DataFrame(columns = ['review','rating'])\n",
    "for index in range(1,6,1):\n",
    "    if index == 4 or index == 5:\n",
    "        samplereviews = coursereviews.loc[index].sample(n = 50000)\n",
    "    else:\n",
    "        samplereviews = coursereviews.loc[index]\n",
    "    sentencelist = sum(list(map(lambda x: sent_tokenize(str(x)),samplereviews['reviews'])),[])\n",
    "    count = len(sentencelist)\n",
    "    if (count > 110000):\n",
    "        sentencelist = random.sample(sentencelist, 110000)\n",
    "    print(count)\n",
    "    trainingData = pd.concat([trainingData, pd.DataFrame(data = [sentencelist, [index]*count], index=['review','rating']).T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sum() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-44b971ef9cba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: sum() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "sum([[1,2,3],[4,5,6]],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 398644 entries, 0 to 93774\n",
      "Data columns (total 2 columns):\n",
      "review    398644 non-null object\n",
      "rating    398644 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 9.1+ MB\n"
     ]
    }
   ],
   "source": [
    "trainingData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData.to_csv(\"trainingData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x = pd.read_csv(\"trainingdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop(labels = ['Unnamed: 0'], inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv(\"traindata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This course is virtually worthless.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I couldn't follow the lectures, and I have a P...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The online course is based on snippets taken f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The instructor frequently refers to concepts t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>This online version of the Yale course was obv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398639</td>\n",
       "      <td>398639</td>\n",
       "      <td>I look forward to put the skills I've acquired...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398640</td>\n",
       "      <td>398640</td>\n",
       "      <td>Best end lab ever!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398641</td>\n",
       "      <td>398641</td>\n",
       "      <td>very useful,build a good foundation!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398642</td>\n",
       "      <td>398642</td>\n",
       "      <td>Fantastic Program</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398643</td>\n",
       "      <td>398643</td>\n",
       "      <td>Good introductory weekly lessons ..</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398644 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                             review  rating\n",
       "0                0                This course is virtually worthless.       1\n",
       "1                1  I couldn't follow the lectures, and I have a P...       1\n",
       "2                2  The online course is based on snippets taken f...       1\n",
       "3                3  The instructor frequently refers to concepts t...       1\n",
       "4                4  This online version of the Yale course was obv...       1\n",
       "...            ...                                                ...     ...\n",
       "398639      398639  I look forward to put the skills I've acquired...       5\n",
       "398640      398640                                 Best end lab ever!       5\n",
       "398641      398641               very useful,build a good foundation!       5\n",
       "398642      398642                                  Fantastic Program       5\n",
       "398643      398643                Good introductory weekly lessons ..       5\n",
       "\n",
       "[398644 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
